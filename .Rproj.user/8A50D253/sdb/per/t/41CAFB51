{
    "contents" : "See the [full list of videos](http://www.dataschool.io/15-hours-of-expert-machine-learning-videos/)\nThe following material constitue the content convered during the course. You are responsible for reading and viewing this material. \n\n##Chapter 1: Introduction \n(slides, playlist)\n\n- Opening Remarks and Examples (18:18)\n- Supervised and Unsupervised Learning (12:12)\n\n\n\n\n##Chapter 2: Statistical Learning \npages 15 - 57\n- what is statistical learning? (2.1)  \n- Assessing model accuracy (2.2)  \n- LAB : Basics. Graphics. Indexing, loading, and summarizing data.   \n\n\n(slides, playlist)\n\n- Statistical Learning and Regression (11:41)\n- Curse of Dimensionality and Parametric Models (11:40)\n- Assessing Model Accuracy and Bias-Variance Trade-off (10:04)\n- Classification Problems and K-Nearest Neighbors (15:37)\n- LAB: Introduction to R (14:12)\n\n\n##Chapter 3: Linear Regression \npage 59 - 126  \n- simple linear regressing (3.1)\n- multiple linear regression (3.2)  \n- categorical predictors, extensions, and problems (3.3)  \n- LAB : Linear Regression. Simple. Multiple. Interactions. Nonlinear transformation. Qualitative predictors. (3.6)  \n\n\n(slides, playlist)\n\n- Simple Linear Regression and Confidence Intervals (13:01)\n- Hypothesis Testing (8:24)\n- Multiple Linear Regression and Interpreting Regression Coefficients (15:38)\n- Model Selection and Qualitative Predictors (14:51)\n- Interactions and Nonlinearity (14:16)\n- Lab: Linear Regression (22:10)\n\n\n##Chapter 5: Resampling Methods \n(slides, playlist)\n\n- Estimating Prediction Error and Validation Set Approach (14:01)\n- K-fold Cross-Validation (13:33)\n- Cross-Validation: The Right and Wrong Ways (10:07)\n- The Bootstrap (11:29)\n- More on the Bootstrap (14:35)\n- Lab: Cross-Validation (11:21)\n- Lab: The Bootstrap (7:40)\n\n\n##Chapter 6: Linear Model Selection and Regularization\npages 203 - 214; 244 - 250\n- subset selection (6.1)  \n- LAB: Sebset selection methods (6.5)\n\n(slides, playlist)\n\n- Linear Model Selection and Best Subset Selection (13:44)\n- Forward Stepwise Selection (12:26)\n- Backward Stepwise Selection (5:26)\n- Estimating Test Error Using Mallow's Cp, AIC, BIC, Adjusted R-squared (14:06)\n- Estimating Test Error Using Cross-Validation (8:43)\n- Lab: Best Subset Selection (10:36)\n- Lab: Forward Stepwise Selection and Model Selection Using Validation Set (10:32)\n- Lab: Model Selection Using Cross-Validation (5:32)\n\n\n##Chapter 7: Moving Beyond Linearity \npages 265-270 ; 282-286 \n- polynomial regression (7.1)  \n- step functions (7.2)  \n- Generalized Additive Models (7.5)\n- LAB: polynomials and steps (7.8.1), GAM (7.8.5)\n\n(slides, playlist)\n\n- Polynomial Regression and Step Functions (14:59)\n- Piecewise Polynomials and Splines (13:13)\n- Smoothing Splines (10:10)\n- Local Regression and Generalized Additive Models (10:45)\n- Lab: Polynomials (21:11)\n- Lab: Splines and Generalized Additive Models (12:15)\n",
    "created" : 1441856697082.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3385097596",
    "id" : "41CAFB51",
    "lastKnownWriteTime" : 1441895766,
    "path" : "~/GitHub/psy532/materials/scope.md",
    "project_path" : "materials/scope.md",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 6,
    "source_on_save" : false,
    "type" : "markdown"
}